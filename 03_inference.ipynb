{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed928843-0c7f-4f82-969d-5828d4385e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32654324-45a7-410e-9dbc-59f6c14a7947",
   "metadata": {},
   "source": [
    "## Inference Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f6dcd0-7fe7-4eab-acfd-eb147f9e3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT=\"CamVid\"\n",
    "ENTITY=\"av-demo\"\n",
    "IMAGE_SHAPE = (720, 960)\n",
    "SEED = 42\n",
    "RUN_NAME = \"inference-1\"\n",
    "JOB_TYPE = \"inference\"\n",
    "\n",
    "MODEL_ARTIFACT_ID = 'av-demo/CamVid/baseline-train-1-saved-model:latest'\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "IMAGE_RESIZE_FACTOR = 1\n",
    "VALIDATION_SPLIT_PCT = 0.2\n",
    "HIDDEN_DIM = 256\n",
    "BACKBONE = \"mobilenetv2_100\"\n",
    "\n",
    "LEARNING_RATE = 1e-3\n",
    "TRAIN_EPOCHS = 1\n",
    "\n",
    "INFERENCE_BATCH_SIZE = 8\n",
    "NUM_WARMUP_ITERS = 10\n",
    "NUM_INFERENCE_BENCHMARK_ITERS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e468c2-a7aa-463d-a233-9ec117fb54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    project=PROJECT,\n",
    "    name=RUN_NAME,\n",
    "    entity=ENTITY,\n",
    "    job_type=JOB_TYPE,\n",
    "    config={\n",
    "        \"model_artifact_id\": MODEL_ARTIFACT_ID,\n",
    "        \"image_shape\": IMAGE_SHAPE,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"image_resize_factor\": IMAGE_RESIZE_FACTOR,\n",
    "        \"validation_split\": VALIDATION_SPLIT_PCT,\n",
    "        \"hidden_dims\": HIDDEN_DIM,\n",
    "        \"backbone\": BACKBONE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"train_epochs\": TRAIN_EPOCHS,\n",
    "        \"inference_batch_size\": INFERENCE_BATCH_SIZE,\n",
    "        \"num_warmup_iters\": NUM_WARMUP_ITERS,\n",
    "        \"num_inference_banchmark_iters\": NUM_INFERENCE_BENCHMARK_ITERS\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0be541-65fc-4903-b34c-6e4602c32767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_traced(artifact):\n",
    "    artifact = run.use_artifact(artifact, type='model')\n",
    "    artifact_dir = Path(artifact.download())\n",
    "    return list(artifact_dir.glob(\"*_traced.pt\"))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864d01d-f8d4-48e0-a3de-d307f580cf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference_time(\n",
    "    model_artifact: str,\n",
    "    image_shape: tuple[int, int],\n",
    "    batch_size: int,\n",
    "    num_warmup_iters: int,\n",
    "    num_iter: int,\n",
    "    seed: int,\n",
    "):\n",
    "    \n",
    "    model_file = _get_traced(model_artifact)\n",
    "    model = torch.jit.load(model_file).cuda()\n",
    "    \n",
    "    dummy_input = torch.randn(\n",
    "        batch_size, 3, image_shape[0] // 2, image_shape[0] // 2, dtype=torch.float\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    starter, ender = (\n",
    "        torch.cuda.Event(enable_timing=True),\n",
    "        torch.cuda.Event(enable_timing=True),\n",
    "    )\n",
    "    timings = np.zeros((num_iter, 1))\n",
    "\n",
    "    print(\"Warming up GPU...\")\n",
    "    for _ in progress_bar(range(num_warmup_iters)):\n",
    "        _ = model(dummy_input)\n",
    "\n",
    "    print(\n",
    "        f\"Computing inference time over {num_iter} iterations with batches of {batch_size} images...\"\n",
    "    )\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for step in progress_bar(range(num_iter)):\n",
    "            starter.record()\n",
    "            _ = model(dummy_input)\n",
    "            ender.record()\n",
    "            torch.cuda.synchronize()\n",
    "            timings[step] = starter.elapsed_time(ender)\n",
    "\n",
    "    return np.sum(timings) / (num_iter * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f0490-16b7-4bce-bd9d-cc44df31ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()\n",
    "torch.cuda.empty_cache()\n",
    "inference_time = benchmark_inference_time(model_artifact=MODEL_ARTIFACT_ID,\n",
    "                    batch_size=INFERENCE_BATCH_SIZE,\n",
    "                    image_shape=IMAGE_SHAPE,\n",
    "                    num_warmup_iters=NUM_WARMUP_ITERS,\n",
    "                    num_iter=NUM_INFERENCE_BENCHMARK_ITERS,\n",
    "                    seed=SEED\n",
    "                    )\n",
    "\n",
    "\n",
    "# wandb.log({\"Model_Parameters\": get_model_parameters(model)})\n",
    "# wandb.log({\n",
    "#     \"Inference_Time\": \n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6184003-e29c-45b7-9c0a-feb77b81d0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a52491-3853-4633-a120-c85f611fd59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.log({\"inference_time\":inference_time})\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
